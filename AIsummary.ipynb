{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl56vZeUzV1t",
        "outputId": "86a07178-f8fa-47b7-f68e-eee684bfdb09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.77.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import os\n",
        "\n",
        "os.chdir(\"/Project_X\")\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('tweets.csv')\n",
        "\n",
        "# Combine all tweets into a single text corpus\n",
        "corpus = ' '.join(df['Tweet Text'])\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['Tweet Text'])\n",
        "\n",
        "# Perform KMeans clustering to find topics\n",
        "num_clusters = 5\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(X)\n",
        "\n",
        "# Get the top terms for each cluster\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the top terms for each cluster\n",
        "for i in range(num_clusters):\n",
        "    print(f\"Cluster {i}:\")\n",
        "    for ind in order_centroids[i, :10]:\n",
        "        print(f\" {terms[ind]}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Assign clusters to tweets\n",
        "df['Cluster'] = km.labels_\n",
        "\n",
        "# Display the DataFrame with clusters\n",
        "print(df[['User Name', 'Tweet Text', 'Cluster']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34qjHw8c1ND1",
        "outputId": "5bfe8a85-577f-44b1-e221-71fddb184473"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0:\n",
            " mexico\n",
            " sewage\n",
            " epa\n",
            " administrator\n",
            " san\n",
            " diego\n",
            " crisis\n",
            " https\n",
            " just\n",
            " tijuana\n",
            "\n",
            "\n",
            "Cluster 1:\n",
            " clean\n",
            " public\n",
            " federal\n",
            " fighting\n",
            " health\n",
            " demanding\n",
            " protect\n",
            " action\n",
            " beaches\n",
            " government\n",
            "\n",
            "\n",
            "Cluster 2:\n",
            " president\n",
            " work\n",
            " wants\n",
            " amp\n",
            " health\n",
            " https\n",
            " crisis\n",
            " mexico\n",
            " border\n",
            " tijuana\n",
            "\n",
            "\n",
            "Cluster 3:\n",
            " need\n",
            " ve\n",
            " river\n",
            " ground\n",
            " shovels\n",
            " fix\n",
            " https\n",
            " federal\n",
            " crisis\n",
            " tijuana\n",
            "\n",
            "\n",
            "Cluster 4:\n",
            " gallons\n",
            " million\n",
            " tijuana\n",
            " pumps\n",
            " sewage\n",
            " flowing\n",
            " billion\n",
            " https\n",
            " toxic\n",
            " day\n",
            "\n",
            "\n",
            "                              User Name  \\\n",
            "0                      Wall Street Apes   \n",
            "1                Supervisor Jim Desmond   \n",
            "2                      Wall Street Apes   \n",
            "3                            Mike Levin   \n",
            "4                        Laura Ingraham   \n",
            "5                        Susan Crabtree   \n",
            "6                          Tyler O'Neil   \n",
            "7                Supervisor Jim Desmond   \n",
            "8                          Amy Reichert   \n",
            "9                            Mike Levin   \n",
            "10            Assemblyman Jeff Gonzalez   \n",
            "11                    RealClearPolitics   \n",
            "12               Supervisor Jim Desmond   \n",
            "13                         Mario Nawfal   \n",
            "14                         Amy Reichert   \n",
            "15                          Mike Garcia   \n",
            "16               Supervisor Jim Desmond   \n",
            "17               Supervisor Jim Desmond   \n",
            "18                    Mayor John McCann   \n",
            "19               Supervisor Jim Desmond   \n",
            "20                         Amy Reichert   \n",
            "21                  Mayor John Franklin   \n",
            "22  The Epoch Timesâ€”Southern California   \n",
            "23            Congresswoman Sara Jacobs   \n",
            "24                         Amy Reichert   \n",
            "25                      Rep. Mike Levin   \n",
            "26                           É±ooble É±uk   \n",
            "27                            KUSI News   \n",
            "28                            KUSI News   \n",
            "29                           bella ross   \n",
            "30                   Times of San Diego   \n",
            "31        Supervisor Terra Lawson-Remer   \n",
            "32                        Neda Iranpour   \n",
            "33                      Rep. Mike Levin   \n",
            "34                         Rudy Ramirez   \n",
            "35                Governor Gavin Newsom   \n",
            "36                 Surfrider Foundation   \n",
            "37        Supervisor Terra Lawson-Remer   \n",
            "\n",
            "                                           Tweet Text  Cluster  \n",
            "0   It Wasnâ€™t Enough For Mexico To Just Send Ameri...        0  \n",
            "1   I was assured today that real, tangible soluti...        2  \n",
            "2   San Diego County Supervisor Jim Desmond showin...        0  \n",
            "3   Hereâ€™s a quick explainer on the Tijuana River ...        3  \n",
            "4   Lee Zeldin: â€œMexicoâ€™s president wants to work ...        2  \n",
            "5   NEW: Trump fires Biden holdover in charge of U...        0  \n",
            "6   How is EPA Administrator Lee Zeldin spending E...        0  \n",
            "7   I witnessed the Tijuana Sewage Crisis firsthan...        0  \n",
            "8   ðŸš¨ALERT: Tijuana is flooded with sewage right n...        4  \n",
            "9   For decades, toxic sewage has poured into the ...        3  \n",
            "10  Today, I joined EPA Administrator @EPALeeZeldi...        0  \n",
            "11  The Tijuana River sewage crisis is worsening, ...        2  \n",
            "12  Starting a critical meeting with EPA Administr...        0  \n",
            "13  ðŸ‡ºðŸ‡¸ ðŸ‡²ðŸ‡½ EPA CHIEF ZELDIN: NEW MEXICAN PRESIDENT ...        2  \n",
            "14  Tijuana is dumping millions of gallons of raw ...        0  \n",
            "15  It was an honor to accompany my friend @epalee...        4  \n",
            "16  Beaches closed for over 1,000 days. Families g...        4  \n",
            "17  Where does Tijuanaâ€™s sewage go?\\n\\nIt depends ...        4  \n",
            "18  Fighting for Clean Water, Public Health, and N...        1  \n",
            "19  Over the past five years, more than 100 billio...        4  \n",
            "20  No, itâ€™s not raining in Tijuana today. What yo...        4  \n",
            "21  Thank you Congressman Issa for working to brin...        0  \n",
            "22  EPA Administrator Lee Zeldin visited San Diego...        0  \n",
            "23  Sewage has flowed through the Tijuana River Va...        3  \n",
            "24  The Tijuana sewage crisis isnâ€™t just Mexicoâ€™s ...        0  \n",
            "25  Iâ€™ve helped secure over $653 million in federa...        3  \n",
            "26  Regardless of how the Tijuana River sewage cri...        2  \n",
            "27  30 MILLION GALLONS per DAY\\n210 MILLION GALLON...        4  \n",
            "28  The Tijuana River Valley sewage crisis is the ...        0  \n",
            "29  dropped some PG-13 content on the @voiceofsand...        4  \n",
            "30  Opinion: Coronado should use its clout to brin...        3  \n",
            "31  Good news: our fight to clean up the Tijuana R...        1  \n",
            "32  Iâ€™m back to work on Monday, thatâ€™s also when t...        2  \n",
            "33  During my meeting with EPA Administrator Zeldi...        3  \n",
            "34  Meeting with Mexican and American officials in...        3  \n",
            "35  NEW: California joins federal &amp; community ...        3  \n",
            "36  Did you know? Every day, millions of gallons o...        2  \n",
            "37  Weâ€™re fighting to clean up the Tijuana River S...        1  \n"
          ]
        }
      ]
    },
    {
      "source": [
        "import openai\n",
        "\n",
        "# Combine tweets in each cluster into a single text\n",
        "clustered_tweets = df.groupby('Cluster')['Tweet Text'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "# Set up OpenAI API key\n",
        "openai.api_key = 'your_api_key_here'\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=openai.api_key) # Initialize the OpenAI client\n",
        "\n",
        "# Function to summarize text using OpenAI GPT-3\n",
        "def summarize_text(text):\n",
        "    # Updated to use client.chat.completions.create\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Or another suitable model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n\\n{text}\"}\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    # Extract the summary from the response\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Apply summarization to each cluster\n",
        "clustered_tweets['Summary'] = clustered_tweets['Tweet Text'].apply(summarize_text)\n",
        "\n",
        "# Display the summaries\n",
        "print(clustered_tweets[['Cluster', 'Summary']])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4sHesOf1a-h",
        "outputId": "bcc1343e-d12d-44b1-f08f-0044d8fe2caa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cluster                                            Summary\n",
            "0        0  Mexico has been sending tens of millions of il...\n",
            "1        1  Leaders, including @epaleezeldin, are fighting...\n",
            "2        2  The text discusses the Tijuana Sewage Crisis a...\n",
            "3        3  The text discusses the Tijuana River sewage cr...\n",
            "4        4  The text discusses the ongoing sewage crisis i...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_tweets.to_csv('clustered_tweets.csv')"
      ],
      "metadata": {
        "id": "wyDL3zVo1Af8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Oj413VT6qGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}